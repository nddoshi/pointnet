{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nddoshi/pointnet/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ewBVgFIiwmK",
        "outputId": "737bf14e-0c87-4495-9f49-fd978c7aa2e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/pointnet\n",
            "Already up to date.\n",
            "/content/pointnet\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%cd /content    # start in content\n",
        "import os       # import os\n",
        "\n",
        "# clone in git repo if it doesn't exist, update it if it does\n",
        "if not os.path.isdir('/content/pointnet'):\n",
        "  !git clone https://github.com/nddoshi/pointnet.git\n",
        "else:\n",
        "  %cd pointnet\n",
        "  !git pull  \n",
        "\n",
        "%cd /content/pointnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAy9tJCgo-TW",
        "outputId": "cd522f66-0b46-4107-f17a-595844ddc804"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/pointnet\n"
          ]
        }
      ],
      "source": [
        "# copy in ModelNet10 data set\n",
        "if not os.path.isdir('/content/datasets'):\n",
        "  %mkdir /content/datasets\n",
        "if not os.path.isdir('/content/datasets/ModelNet10'):\n",
        "  %cd /content/datasets\n",
        "  !wget http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\n",
        "  !unzip -q ModelNet10.zip\n",
        "  %rm -rf __MACOSX\n",
        "  %rm ModelNet10.zip\n",
        "\n",
        "%cd /content/pointnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnLCPO1HlP3h",
        "outputId": "0c559e4d-1d53-4b58-b301-09b649038b53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: path in /usr/local/lib/python3.7/dist-packages (16.2.0)\n",
            "1\n",
            "Tesla K80\n"
          ]
        }
      ],
      "source": [
        "# imports \n",
        "import math\n",
        "import random\n",
        "import sys,os\n",
        "import torch\n",
        "import argparse\n",
        "!pip install path\n",
        "from path import Path\n",
        "from source import model\n",
        "from source import dataset\n",
        "from source import utils\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "random.seed = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eSM-B-Bkn9rb"
      },
      "outputs": [],
      "source": [
        "def pointnetloss(outputs, labels, m3x3, m64x64, alpha=0.0001):\n",
        "    criterion = torch.nn.NLLLoss()\n",
        "    bs = outputs.size(0)\n",
        "    id3x3 = torch.eye(3, requires_grad=True).repeat(bs, 1, 1)\n",
        "    id64x64 = torch.eye(64, requires_grad=True).repeat(bs, 1, 1)\n",
        "    if outputs.is_cuda:\n",
        "        id3x3 = id3x3.cuda()\n",
        "        id64x64 = id64x64.cuda()\n",
        "    diff3x3 = id3x3-torch.bmm(m3x3, m3x3.transpose(1, 2))\n",
        "    diff64x64 = id64x64-torch.bmm(m64x64, m64x64.transpose(1, 2))\n",
        "    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3)+torch.norm(diff64x64)) / float(bs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO4M5ySoolta",
        "outputId": "d428e531-9c0f-414b-9850-4b334286ab2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "Train dataset size:  3991\n",
            "Valid dataset size:  908\n",
            "Number of classes:  10\n",
            "[Errno 17] File exists: './checkpoints/'\n",
            "Start training\n",
            "[Epoch: 1, Batch:   10 /  125], loss: 1.968\n",
            "[Epoch: 1, Batch:   20 /  125], loss: 1.592\n",
            "[Epoch: 1, Batch:   30 /  125], loss: 1.498\n",
            "[Epoch: 1, Batch:   40 /  125], loss: 1.292\n",
            "[Epoch: 1, Batch:   50 /  125], loss: 1.153\n",
            "[Epoch: 1, Batch:   60 /  125], loss: 1.158\n",
            "[Epoch: 1, Batch:   70 /  125], loss: 1.053\n",
            "[Epoch: 1, Batch:   80 /  125], loss: 1.016\n",
            "[Epoch: 1, Batch:   90 /  125], loss: 0.975\n"
          ]
        }
      ],
      "source": [
        "# arguments\n",
        "\n",
        "root_dir = '../datasets/ModelNet10'\n",
        "batch_size=32\n",
        "lr =1e-3\n",
        "epochs=15\n",
        "save_model_path = './checkpoints/'\n",
        "\n",
        "\n",
        "path = Path(root_dir)\n",
        "folders = [dir for dir in sorted(\n",
        "    os.listdir(path)) if os.path.isdir(path/dir)]\n",
        "classes = {folder: i for i, folder in enumerate(folders)}\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    utils.PointSampler(1024),\n",
        "    utils.Normalize(),\n",
        "    utils.RandRotation_z(),\n",
        "    utils.RandomNoise(),\n",
        "    utils.ToTensor()\n",
        "])\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "pointnet = model.PointNet()\n",
        "pointnet.to(device)\n",
        "optimizer = torch.optim.Adam(pointnet.parameters(), lr=lr)\n",
        "\n",
        "train_ds = dataset.PointCloudData(path, transform=train_transforms)\n",
        "valid_ds = dataset.PointCloudData(\n",
        "    path, valid=True, folder='test', transform=train_transforms)\n",
        "print('Train dataset size: ', len(train_ds))\n",
        "print('Valid dataset size: ', len(valid_ds))\n",
        "print('Number of classes: ', len(train_ds.classes))\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_ds, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(dataset=valid_ds, batch_size=batch_size*2)\n",
        "\n",
        "try:\n",
        "    os.mkdir(save_model_path)\n",
        "except OSError as error:\n",
        "    print(error)\n",
        "\n",
        "print('Start training')\n",
        "for epoch in range(epochs):\n",
        "  pointnet.train()\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "      inputs, labels = data['pointcloud'].to(\n",
        "          device).float(), data['category'].to(device)\n",
        "      optimizer.zero_grad()\n",
        "      outputs, m3x3, m64x64 = pointnet(inputs.transpose(1, 2))\n",
        "\n",
        "      loss = pointnetloss(outputs, labels, m3x3, m64x64)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # print statistics\n",
        "      running_loss += loss.item()\n",
        "      if i % 10 == 9:    # print every 10 mini-batches\n",
        "          print('[Epoch: %d, Batch: %4d / %4d], loss: %.3f' %\n",
        "                (epoch + 1, i + 1, len(train_loader), running_loss / 10))\n",
        "          running_loss = 0.0\n",
        "    \n",
        "  pointnet.eval()\n",
        "  correct = total = 0\n",
        "\n",
        "  # validation\n",
        "  if valid_loader:\n",
        "      with torch.no_grad():\n",
        "          for data in valid_loader:\n",
        "              inputs, labels = data['pointcloud'].to(\n",
        "                  device).float(), data['category'].to(device)\n",
        "              outputs, __, __ = pointnet(inputs.transpose(1, 2))\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "              total += labels.size(0)\n",
        "              correct += (predicted == labels).sum().item()\n",
        "      val_acc = 100. * correct / total\n",
        "      print('Valid accuracy: %d %%' % val_acc)\n",
        "  # save the model\n",
        "\n",
        "  checkpoint = Path(save_model_path)/'save_'+str(epoch)+'.pth'\n",
        "  torch.save(pointnet.state_dict(), checkpoint)\n",
        "  print('Model saved to ', checkpoint)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
